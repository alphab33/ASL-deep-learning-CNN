# ASL-deep-learning-CNN

This project demonstrates the use of Convolutional Neural Networks (CNNs) to recognize hand signs representing letters of the alphabet (A, B, C) in sign language.

Contents:
1. Introduction
2. Getting Started
3. File Descriptions
4. Usage
5. Dependencies
6. License

1. Introduction:
   This project aims to recognize hand signs from images using CNNs. It includes code to load the sign language dataset, build and train a CNN model, evaluate the model's performance, and visualize mislabeled examples.

2. Getting Started:
   To run the project, follow these steps:
   - Ensure you have Python 3.7 or later installed.
   - Install the required dependencies listed in the 'Dependencies' section.
   - Clone or download the project repository to your local machine.

3. File Descriptions:
   - sign_language_model.py: Python module containing the SignLanguageModel class, which encapsulates the functionality for loading the dataset, building, training, and evaluating the CNN model.
   - main.py: Script file to run the CNN model, including loading data, building and training the model, evaluating its performance, and visualizing mislabeled examples.
   - readme.txt: This file, providing an overview of the project and instructions for getting started.
   - datasets/: Directory containing the sign language dataset.

4. Usage:
   - Run the main.py script to execute the project. Follow the instructions provided in the script file to load data, build and train the model, and visualize results.

5. Dependencies:
   - Python 3.7 or later
   - TensorFlow 2.x
   - NumPy
   - Matplotlib

For more information or assistance, contact alphabbarry4@gmail.com
